% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/01_get_embeddings.R
\name{save_embeddings}
\alias{save_embeddings}
\title{Save Text Embeddings to an HDF5 File}
\usage{
save_embeddings(
  data,
  post_id = NULL,
  time = NULL,
  content = NULL,
  model_name = "twitter/twhin-bert-base",
  batch_size = 32L,
  max_length = 512L,
  use_fp16 = TRUE,
  chunk_size = 512L,
  h5_fileprefix = "embeddings_",
  save_dir = NULL,
  python_version = "3.13",
  conda_path = NULL,
  conda_env_path = NULL,
  conda_env_name = "conda-coorsim",
  ask = TRUE,
  force = FALSE,
  verbose = TRUE
)
}
\arguments{
\item{data}{A `data.frame` or `data.table` containing the input text data.}

\item{post_id}{Character. Column name in `data` containing unique post identifiers. If `NULL`, 
the function attempts to detect it automatically.}

\item{time}{Character. Column name in `data` containing timestamps. If `NULL`, the function 
attempts to detect it automatically.}

\item{content}{Character. Column name in `data` containing text content to embed. If `NULL`, 
the function attempts to detect it automatically.}

\item{model_name}{Character. Name of the transformer model to use for generating embeddings. 
Defaults to `"twitter/twhin-bert-base"`.}

\item{batch_size}{Integer. Number of texts processed per batch when generating embeddings. 
Defaults to `32L`.}

\item{max_length}{Integer. Maximum token length for transformer-based embedding generation. 
Defaults to `512L`.}

\item{use_fp16}{Logical. Whether to use half-precision floating point (`fp16`) for faster 
computation on GPUs. Defaults to `TRUE`.}

\item{chunk_size}{Integer. The number of observations per chunk when storing embeddings in the 
HDF5 file. Defaults to `512L`.}

\item{h5_fileprefix}{Character. Prefix for the generated HDF5 filename. Defaults to `"embeddings_"`.}

\item{save_dir}{Character. Directory where the HDF5 file will be saved. If `NULL`, defaults to the 
working directory.}

\item{python_version}{Character. The Python version to use when retrieving embeddings. Defaults to `"3.13"`.}

\item{conda_path}{Character. The path to the Conda installation to use. If `NULL`, the function 
attempts to detect an existing installation.}

\item{conda_env_path}{Character. The path where the Conda environment should be created or used. 
If `NULL`, the default Conda environment location is used.}

\item{conda_env_name}{Character. The name of the Conda environment where embeddings will be 
generated. Defaults to `"conda-coorsim"`.}

\item{ask}{Logical. Whether to prompt the user for confirmation before installing Conda or dependencies.
Defaults to `TRUE`.}

\item{force}{Logical. If `TRUE`, forces reinstallation of dependencies even if they are already installed.
Defaults to `FALSE`.}

\item{verbose}{Logical. If `TRUE`, prints progress messages. Defaults to `TRUE`.}
}
\value{
Invisibly returns `NULL`. The function is executed for its side effects of generating 
and storing text embeddings.
}
\description{
This function retrieves text embeddings using a transformer model, processes the 
input data, and stores the resulting embeddings in an HDF5 file along with metadata for efficient 
retrieval and analysis.
}
\details{
The function performs the following steps:
\itemize{
  \item Ensures `data` contains the required columns (`post_id`, `time`, `content`), renaming them if necessary.
  \item Removes duplicate entries based on `post_id`.
  \item Converts `time` to a UNIX timestamp format for interoperability.
  \item Sorts the dataset by `time` to enable fast querying.
  \item Generates text embeddings using the specified transformer model.
  \item Stores embeddings and metadata (post IDs and timestamps) in an HDF5 file using chunked storage.
}

The HDF5 file structure includes:
\itemize{
  \item `"metadata/time"`: Vector of timestamps (UNIX format).
  \item `"metadata/post_id"`: Vector of post IDs.
  \item `"embeddings"`: Matrix of text embeddings stored in chunks.
}

The chunked storage format enables efficient retrieval of embeddings by time range.
}
